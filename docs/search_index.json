[
["index.html", "経済学と反事実分析 接触篇 Economics and Counterfactual Analysis: A Contact 1 概要", " 経済学と反事実分析 接触篇 Economics and Counterfactual Analysis: A Contact ill-identified 2020-02-23 1 概要 第83回Tokyo.Rのエントリ. 前回の戦後処理に時間を取られたので, 手抜き回. 前回にも言及した Igami (2018) の研究に関連して, 構造推定についてもう少し詳しい話をしようと思っていたが, 残り時間の問題から動学構造推定は難しいと判断した. しかしアンケート至上主義なので経済学のネタは外せないから, 準備の簡単な静学構造推定の話をとりあえずやることにした. 静学構造推定は「動学」ではないので時間変化を考えないタイプの理論モデルを推定する一連のテクニックである. 今回の話は比較的簡単かつ昔から知られている話だから大学の経済学部でも授業で取り上げられることもあろう. 知ってる人も多いかもしれない. 具体的には, 生産関数を構造推定するOP法(Olley and Pakes 1996)およびLP法(Levinsohn and Petrin 2003)をRでやる. プログラム全文等付属物はこちらにある https://github.com/Gedevan-Aleksizde/20190125_tokyor References "],
["イントロダクション.html", "2 イントロダクション 2.1 構造推定とは 2.2 因果推論と何が違うのか 2.3 今回取り組む問題", " 2 イントロダクション 2.1 構造推定とは では構造推定とは何だろうか. 構造推定で検索すると, 名前が似ているが違うものがいくつか出てくる. 2.1.1 構造方程式モデリング 例えば構造方程式モデル(SEM)というものがある. これは変数間の関係構造を同時線形方程式で表したもので, 因果推論のフレームワークの原型ともいえるものだが, 構造推定とは違う. 2.1.2 構造時系列モデル 構造ベクトル自己回帰モデル (Structural VAR) とか, ベイズ構造時系列モデル (BSTS) というものがある. 通常のVARは複数の変数の時系列変化を扱うモデルで, それぞれの変数が過去の値にのみ依存して決まる回帰モデルなのに対して, 構造VARは現在の別の変数にも依存する, 同時決定的な時系列モデルである1. ベイズ構造時系列モデルの「構造時系列」はHarveyのいう構造時系列モデルのことを指す(Scott and Varian 2014). これは89年とかなり古い教科書なので私も読んだことがないが, Lütkepohl (2007), p. 618によればローカルトレンドモデルを基本とした時系列モデルらしいので, 多変量時系列モデルというわけでもなく, 状態空間モデルに属する. これらも構造推定とは関係ない. 2.1.3 構造型モデル いちおう過去のTokyo.Rの発表ネタとかぶらないか確認したところ, こんなものを見つけた. Rで学ぶ『構造型モデル de 倒産確率推定』 「構造型モデル」という名前も構造推定と似ている. いちおう元になった Merton (1974) の論文も確認した. しかしこれも構造推定ではない. 構造推定の定義について, 多くの人は Reiss and Wolak (2007) を挙げるが, この本はとにかく分厚くて高いので私は持っていない. 前回で触れたように,観察されたデータにそのまま回帰式や他の関数を当てはめても因果関係を知ることはできない. そこで, いくつかの要素が必要になる. そこで構造推定は仮定によって構造を特定しようとした. 北村 (2016, 応用ミクロ計量経済学の手法と論点)は一般的な型はないとしつつ, その解説を要約すると3つの特徴があるとしている. 経済理論モデルであること 確率モデルであること データに基づいて推定されていること (1)はいわゆるルーカス批判 Lucas (1976) を受けて, 彼の批判を克服できるような経済理論に基づいたモデルづくりを意識するようになった. (2)はちょっとわかりづらい. 回帰分析だって正規分布を暗に仮定しているから確率モデルになる. しかしここでは, 観察できないものと, できるものの不確実性を考慮しているという意味である. 例えば測定誤差や, 分析者には観測できないが, 経済活動の当事者は知っている情報というものがある. これらを無視した推定はしばしばバイアスを引き起こすが, 構造推定ではモデルにこのような仮定を取り込む. (3) は, 完全な架空の話ではなく, なるべく現実と整合するために観測されたデータに基づいてパラメータを決定するということである. よって, 最初に挙げた「構造方程式モデリング」や「Mertonの構造型モデル」は経済理論に基づいた構造を表現していないため構造推定ではない. ただし構造時系列モデルは, 実は80年代にマクロ経済モデルとして利用された歴史がある. 経済理論に基づかないという批判は当時からあったものの, 単に予測するだけなら問題ないということで使われていた. しかし, 「どうなるか」と「なぜそうなるのか」のどちらを求めているかと言えば前者であり, 原因を分析することはできない2. 一般に定まった方法はないが, かといって完全な無手勝流ではない. 大学院のコアコースで教えるモデルはだいたい決まっており, 多くの研究も先行研究のフレームワークを応用していることが多い. 2.2 因果推論と何が違うのか 以前にも紹介したようなRCT, 準実験(操作変数法, 傾向スコア法, DID, RDD) なども, 「反事実的な因果推論」と呼ばれる. しかしこれらは経済学の理論仮説に基づく因果関係ではなく, ランダム化と比較によって「平均処置効果」を求めるフレームワークである3. 一方で構造推定は実際のデータと理論モデルを融合させた結果なので, 本来の意味で現実には起こり得なかったこと (反事実) を推論するフレームワークである. 具体例を挙げよう. 今回は経済学における生産関数の推定の例を紹介する. 原材料を投入し, 財を生産する, その変換ルールを関数に表したものを生産関数という. 例えば, 資本(\\(K\\)apital4)と労働力(\\(L\\)abor force), \\(Y\\)は出力, つまり生産量なので, 生産関数を以下のように表せる \\[\\begin{aligned} Y= &amp; F(K,L)\\end{aligned}\\] この生産関数の形状が分かれば, 実際のデータとの残差から, 数値に表れない生産性 (TFP) を計測する (残差分析) もし設備投資を増やしたら (\\(K\\)を増加させたら) どれくらい生産量が増えるか もしパラメータが変化したら, 生産力はどう変化するか (比較静学分析) と言ったことがわかる.経済学部出身者ならば, ミクロ経済学の授業で聞いた覚えがあるだろう. しかし, データから推定した係数が「もし変わったら」というのは, 本質的に現実に起こっていない事象について話していることになる. 同等のことを因果推論でやるとすれば, 両方のケースについて実際に観測したデータに基づいて差を比較しなければならない. つまり, 単にデータを近似しただけの関数では, これらのことを言う根拠として弱い. 経済学ではRCTや準実験アプローチは誘導形 (reduced form) 推定5とも呼ばれ, 構造推定派と誘導形推定派は数年前までお互い相手のアプローチの問題点を指摘し激しく論争していた. その結果, 現在ではそれぞれのアプローチでできることの限界がはっきりしてきたため, 論争というほどのことはない6. 両者の使い分けとしては, 構造推定は経済理論モデルというある意味「架空のもの」に基づいて未来に起こりうることについての分析もできるが, 因果推論は実態としては実験計画法と本質的に同じで統計学の理論に基づいて観察できたデータから事後評価するアプローチである. よってしばしば, 構造推定は反事実(反実仮想)シミュレーション7, 因果推論はプログラム(政策)評価とか介入(intervention)といって呼び分けられる8. そして構造推定は理論仮説に強く依存したフレームワークであるので, 仮説が妥当なのかはよく注意が必要である. ただし, かといって因果推論が仮定に依存しないというのも完全な誤りである. 前回でも言及したが, 因果推論であっても必ず仮定が存在するので, それを無視して計算した平均値の差が因果効果を意味するとは限らない. 2.3 今回取り組む問題 動学構造推定はテクニカルでなんかすごいことをやってるという印象を簡単に与えられる. しかし, 今回は時間がないのでもう少し簡単にできるほうをやる. 前回話題にしたのは「動学的」構造推定であり, 時間変化を取り入れたモデルを扱うジャンルである. 一方で, 今回は考慮しない「静学的」構造推定の具体例を紹介する. といっても昔からある研究なので, すでに日本語の講義スライドもネット上に転がっていたりするし, もしかしたら発表者の中にも授業でやったことがあると言う人がいるかもしれない. 今回は特に, 生産関数の推定の問題を例にする. 生産関数をどういう形にするかはいろいろだが, よく使われるものの1つに コブ=ダグラス型生産関数がある9. 特に, 一企業の生産関数を, \\[\\begin{aligned}Y=f(K,L):= &amp; \\alpha K^{\\beta_{K}}L^{\\beta_{L}}\\end{aligned}\\] という指数関数で表す10. \\(\\alpha,\\beta_{K},\\beta_{L}\\) はパラメータである. \\(\\beta_{K}=\\beta_{L}=0.5\\) の場合, 図2.1 のような形状になる.) 図2.1: コブ=ダグラス生産関数の形状 References "],
["どう推定するか.html", "3 どう推定するか 3.1 なぜ生産関数を知りたいのか 3.2 パネルデータ分析と観測されない効果 3.3 動学パネルデータ分析 3.4 企業内部の意思決定を考える 3.5 OPモデルの回帰モデルとしての意味 3.6 モデルの事後診断 3.7 OP法以降の研究", " 3 どう推定するか 経済学部の計量経済学の講義では, 回帰分析で生産関数の推定をやるところも多いと思う. 前節の生産関数は, \\(Y\\)を被説明変数, \\(K,L\\) を説明変数としても線形式ではない. しかし, \\(Y,K,L\\)がいずれもゼロ以下になりえないことに着目すると, 対数を取って以下のようになる(いわゆる対数線形回帰モデル). \\[\\begin{gathered}\\ln Y=\\ln\\alpha+\\beta_{K}\\ln K+\\beta_{L}\\ln L\\end{gathered}\\] となる. つまり, おなじみの最小二乗法(OLS)で計算できる. 観測できなかった\\(\\alpha\\)も, 切片パラメータ として推定できることになる. 以降はそれぞれの対数を\\(y,\\beta_{A},k,l\\)に置き換えて, \\[\\begin{aligned} y &amp;= \\beta_{A}+\\beta_{K}k+\\beta_{L}l+\\varepsilon\\end{aligned}\\tag{3.1}\\] という線形回帰モデルを考える. しかし以前書いたように, 経済学の文脈では非線形だろうが線形式だろうがデータに関数を当てはめただけでは用をなさない. 経済理論に即して, 発生しうる問題を排除した方法で推定しなければならない. つまり, 現在ではOLSでは生産関数のパラメータを推定するには不十分と考えられている. 発表時間の問題から, スライドでは大幅に省略しているが, ここでは冗長気味にパネルデータ分析の発展の経緯も合わせて説明していく11. 現在の経済学の観点からすると, (3.1)をそのままOLSで推定するのをためらう大きな理由は以下の3つである. 企業特有の効果が存在する 需要要因を考慮していない セレクションバイアス 3.1 なぜ生産関数を知りたいのか しかし, テクニカルなことを説明する前に, そもそもなぜこのようなことをするのかを表明したほうがよかろう. 今回, 最後に紹介するのは Olley and Pakes (1996) の研究で, 彼らは法規制が産業の生産性にどう影響するかを知ることを研究目的としていた. では, 生産性なるものをどう計測すればいいのだろうか. 経済学には全要素生産性 (TFP; total factor productivity)という概念がある. これは, 投入したリソースの量では説明できない生産量の多さを生産性と定義した概念で, 実際には推定した生産関数による生産量の予測値 (理論値) と実測値の誤差で計測する . 例えば今回はコブ=ダグラス型関数で, モデルの仮定から, 物的・人的リソースによる生産量は\\(K^{\\beta_{K}}L^{\\beta_{L}}\\)の部分になる. よってTFPを計算する式は, \\[\\begin{aligned}\\mathit{TFP}:= &amp; \\frac{Y}{K^{\\beta_{K}}L^{\\beta_{L}}}\\end{aligned}\\] となる. もしTFPを毎年計測して値に変化があるのなら, それは技術進歩に由来する生産性の向上であると見なせる(正確にはこれはソロー残差とか成長会計モデルとか呼ばれる)12. さらに, (3.1)からも分かるように, 対数の性質には \\(\\ln(x/y)=\\ln x-\\ln y\\)というものがある(高校数学でも扱うはずだ). よって, 仮に(3.1)の係数パラメータ\\(\\beta_{K},\\beta_{L}\\)を求められれば, \\[\\begin{aligned} \\ln(\\mathit{TFP}):= &amp; y-\\hat{\\beta}_{K}k-\\hat{\\beta}_{L}l\\\\ \\therefore\\mathit{TFP}= &amp; \\exp(y-\\hat{\\beta}_{K}k-\\hat{\\beta}_{L}l)\\end{aligned}\\] となる. よって回帰分析で推定した式を使うと, TFPは\\(\\alpha\\)だけでなく誤差項も含まれることになる. TFPは回帰モデルの残差に依存する. ではここで, 当てはまりの良さのために生産関数の形状を変えたらどうなるだろうか? 当てはまりを良くするのなら, いろいろなモデルを試していくらでも生産量の予測誤差の少ないモデルを作り出すことができる. しかしそこから計算した残差は一体何を意味するのだろうか? 機械学習や統計モデリングというと, MSEとか対数損失がどれくらい小さいかというのがモデルの良さの指標だと語られることがしばしばあるが, しかしこのようにそれが活用方法としての全てではない. そしてTFPや生産性といった概念は, このように生産構造をどう仮定するかに強く依存することに注意する. 分析にはかならず「ある仮定のもとで…」という前置きが存在する. 「生産性」という抽象的な概念が何を意味するのか, 何を言っているのかはよく考えるべきであろう13. 3.2 パネルデータ分析と観測されない効果 「企業特有の効果」とは, 特定の企業だけが「特殊な技術を持っている」「優秀な人材が集まっている」など, 単純な量だけでは捉えきれない情報を意味する. つまり, 企業ごとに異なる\\(\\omega_{i}\\)が生産量に影響していると考える. \\[\\begin{aligned} y_{i}= &amp; \\beta_{A}+\\beta_{K}k_{i}+\\beta_{L}l_{i}+\\omega_{i}+\\varepsilon_{i}\\end{aligned}\\] \\(\\omega_{i}\\)は観測できないので, このまま \\((y_{i},k_{i},l_{i})\\)のデータで回帰すると, \\(\\omega_{i}\\)は定数項\\(\\beta_{0}\\)または誤差項\\(\\varepsilon\\)に吸収される. \\(\\omega_{i}\\)が\\(k_{i},l_{i}\\)と全く相関しない変数ならば, \\(\\beta_{A}\\)と\\(\\omega_{i}\\)を識別できないものの, 少なくとも\\(\\beta_{K},\\beta_{L}\\)の推定はできる. このような問題をどう解決すれば良いだろうか? まずは問題1だけを考えよう. \\(\\omega_{i}\\)は観測できないが, では推定できないだろうか? つまり, 同一の企業の情報を何度も観測しすれば, そこから推定できないか, というアイディアである. これがパネルデータ分析のスタート地点になる. パネルデータとは, 同一個体を追跡して複数時点で観測したデータである(表3.1). 表3.1: パネルデータの例 企業ID 時期 生産量 資本 労働力 001 2019Q1 100 10 10 001 2019Q2 110 11 10 001 2019Q3 90 12 12 001 2019Q4 120 14 13 002 2019Q1 80 5 5 002 2019Q2 90 6 5 よって, 企業\\(i=1,\\cdots,N\\)ごとに, \\(t=1,\\cdots,T\\)の観測がある. そこで以降は回帰モデルを以下のように書く. \\[\\begin{aligned} y_{i,t}= &amp; \\beta_{A}+\\beta_{K}k_{i,t}+\\beta_{L}l_{i,t}+\\omega_{i}+\\varepsilon_{i,t}\\end{aligned}\\tag{3.2}\\] ここではひとまず, \\(\\omega_{i}\\)が企業\\(i\\)ごとに異なるが, 時間\\(t\\)に対しては変化しないと考えておこう. また, 問題1だけを考えるにあたって, \\(\\omega_{i}\\)は\\(k_{i,t},l_{i,t}\\)と相関しないとしておこう. このような\\(\\omega_{i}\\)を観測されない個別効果(unobserved indivisual effect) という. さらに追加の仮定として, \\(\\omega_{i}\\)が定数である場合, ダミー変数を作成することでOLSであるかのように\\(\\omega_{i}\\)を推定できる14. これをLSDV推定量という. また別の解き方としては, (3.2)を企業ごとに平均を取った場合を考える. \\[\\begin{aligned} \\bar{y}_{i}= &amp; \\beta_{A}+\\beta_{K}\\bar{k}_{i}+\\beta_{L}\\bar{l}_{i}+\\bar{\\omega}_{i}+\\varepsilon_{i,t}\\end{aligned}\\tag{3.3}\\] このとき, \\(\\omega_{i}\\)は企業ごとに一定なので, \\(\\bar{\\omega}_{i}=\\omega_{i}\\)である. よって, (3.2)から(3.3)を引いてからOLSで計算することでも同じ推定結果が得られる. こちらの方法は固定効果(FE; fixed effect)推定量またはグループ内(within)推定量と呼ばれる15. 一方で, \\(\\omega_{i}\\)が定数項ではなく確率変数の可能性もある. つまり, 企業ごとに異なる\\(\\omega_{i}\\)は実は期待値をとればゼロになる確率変数にすぎず, 定数項に見えたものは確率的なゆらぎに過ぎないかもしれない. この仮定の元に考案されたのが変量効果(RE; random effect)モデルである. REモデルは数学的に分散不均一な回帰モデルと同一のため, 実質的に一般化最小二乗法(GLS)と同じである16.. 3.3 動学パネルデータ分析 このように, 観察できない要因があってもパネルデータがあれば理論上は推定が可能になる. しかし, Mairesse (1990)17はこれまで紹介した方法とほぼ同じやり方で企業の生産関数を推定したところ, 観測されない効果を識別しようと複雑に差分を取れば取るほど, 係数の推定値が小さくなることを発見した. 彼はこの原因の仮説をいくつか挙げている. 内生性の問題. 個別効果\\(\\omega_{i}\\)は物理的なものではなく, 環境, 経営者の手腕といったものに由来するのなら, 他の説明変数\\(k,l\\)の決定に影響している. 企業の意思決定のラグ. 経営者が誤差項として現れる短期的な変化, つまり直前の\\(\\varepsilon_{i,t-1}\\)に対応して\\(k_{i,t},l_{i,t}\\)を決定しているなら, 誤差項と説明変数が相関しており, 単純な差分では推定できない. 同時決定の問題. 測定誤差. 各変数に測定誤差があれば, 差を取ることで打ち消される. これらの問題への対応として考えられるのが, 操作変数である. (3.2)に, 被説明変数\\(y_{i,t}\\)の自己回帰項を追加する. \\[\\begin{aligned} y_{i,t}= &amp; \\beta_{A}+\\beta_{K}k_{i,t}+\\beta_{L}l_{i,t}+\\rho y_{i,t-1}+\\varepsilon_{i,t}\\end{aligned}\\tag{3.4}\\] こういう自己回帰項を含むモデルを扱う分野はパネルデータ分析のなかでも特に動学パネルデータ分析と呼ばれる. このあたりの問題も 奥井 (2016) や Wooldridge (2010), Ch. 11 で丁寧に説明されている18ので冗長だが, 一応簡単に述べておく. 前節のアイディアを流用すれば, Within推定量の応用で時間平均\\(\\bar{y}_{i}=(T-1)^{-1}\\sum_{t=2}^{T}y_{i,t}\\)を取ることが考えられる. しかし, パネルデータでは\\(N\\)が大きいが\\(T\\)は小さいことが多いため, 一致推定量とみなせない. 一方で, 1階差分(FD) 推定量というものがある. これはある意味DID推定量と同じである. 差分演算子を \\(\\Delta x_{t}:=x_{t}-x_{t-1}\\)というふうに定義する. (3.4)の両辺から\\(y_{i,t-1}\\)を引くと, 以下のようになる. \\[\\begin{aligned} \\Delta y_{i,t}= &amp; \\beta_{K}\\Delta k_{i,t}+\\beta_{L}\\Delta l_{i,t}+\\rho\\Delta y_{i,t-1}+\\Delta\\varepsilon_{i,t}\\end{aligned}\\] しかし, \\(\\Delta y_{i,t-1}=y_{i,t}-y_{i,t-1}\\)から, \\(\\Delta\\varepsilon_{i,t}=\\varepsilon_{i,t}-\\varepsilon_{t-1}\\)と相関が存在する. そこで, \\(\\varepsilon_{i,t-1}\\)より過去の\\(y_{i,t-2},\\cdots\\)を操作変数として使う方法が提案されている. それが Anderson and Hsiao (1981);Anderson and Hsiao (1982) モデルや, Arellano and Bond (1991), Blundell and Bond (1998) のGMM推定法である(いわゆる階差GMMとシステムGMM). しかし, これらは実際に操作変数として意味のある変数なのかということを深く議論せずに\\(\\{y_{i,t-2},\\cdots\\}\\)を操作変数に利用している. その場合, 上記で挙げたような意思決定が存在するかどうかを検証できないし, これらの推定量には過剰識別や弱相関操作変数の問題が発生することが指摘されており, 妥当性に疑問が残る. 3.4 企業内部の意思決定を考える しかし, 経済学の理論では, 観察される経済データは市場が需要と供給のバランスを取った結果である. これが2つ目の「需要要因を考慮していない」という話になる. 企業が需要を全く考えずに事業計画を立てるとは考えにくいため, この\\(\\omega_{i}\\)が間接的に\\(k_{i},l_{i}\\)に影響している可能性は十分ある. また, 企業は新規立ち上げだったり倒産したりする. 現実のパネルデータはしばしば欠落がある. そのようなデータでそのまま推定しようとしたらどうだろうか. このようなパネルデータでの内生性に対処する推定方法に関する研究はいくつもあり, 特によく出てくるものとしてFEIVモデル, がある. さらに, Olley and Pakes (1996), Levinsohn and Petrin (2003) はこれらの動学パネルデータ分析の方法から一歩進んで, 企業の意思決定の構造をモデル化した生産関数を考え19, 操作変数を使わずに内生性の問題に対処した方法を提案している (一般にはOPの方法はコントロール関数アプローチと呼ばれる)20. そこで今回はOlleyらのフレームワークを詳しく説明する. なお, 以降は(3.2)式をもとに説明するが, 各企業で同じことが言えるため\\(i\\)を省略して書く. OPでは, 観察されない効果\\(\\omega_{t}\\)は企業の経営者は知ることができるが, データとして現れないため分析者には観測できない, 企業固有の生産能力を表す成分である. \\(\\omega_{t}\\)は他の変数の影響を受けない(外生的)が, 自身の過去の値からは影響を受けると仮定する. つまり1次のマルコフ過程であるとする. \\[\\begin{aligned} \\omega_{t}\\sim &amp; P(\\omega\\mid\\omega_{t-1})\\end{aligned}\\] \\(t\\)期の始めに経営者は\\(\\omega_{t}\\)を観測して, これをもとに今期の経営計画を決定, つまり, 純キャッシュフローの割引現在価値を最大化できるように\\(k_{t},l_{t}\\)を決めていると仮定する. そこで, 動学的なモデルを想定する. 企業の\\(t\\)時点現在での収益を\\(\\pi_{t}(\\omega_{t},k_{t},l_{t})\\)として, 投資\\(\\mathit{inv}_{t}\\)に対する費用を \\(c(\\mathit{inv}_{t})\\)とする. 経営者が最適化する現在の価値関数 (value function)を \\(V_{t}(\\omega_{t},k_{t},l_{t})\\)とすると21, 動学モデルでは単に現在の価値関数を最大化することが最適化に繋がるとは限らない. 経営者は, これらを把握した上で, 割引現在価値を最大化するように行動する. つまり, 以下のような \\(V^{\\ast}\\)の達成を目指す. \\[\\begin{aligned} V^{\\ast}= &amp; \\max_{\\{k_{t},l_{t}\\}}\\sum_{t=0}^{\\infty}\\delta V_{t}(\\cdots)\\end{aligned}\\] これは無限和なのでそのまま計算するのは難しいが, 一定の条件下では上記の最適化問題の解が以下(3.5)のようなベルマン方程式 (Bellman equation) の解と同じであることが分かっている22. \\[\\begin{aligned} V_{t}(\\omega_{t},k_{t},l_{t})= &amp; \\max_{k_{t},l_{t}}\\left\\{ \\Phi,\\sup_{i_{t}\\geq0}\\pi_{t}(\\omega_{t},k_{t},l_{t})-c(\\mathit{inv}_{t})+\\delta\\mathrm{E}\\left[V_{t+1}(\\cdots)\\right]\\right\\} \\end{aligned}\\tag{3.5}\\] ベルマン方程式が意味するところは, \\(t,t+1\\)という2時点間の関係さえ分かれば上記の無限和の問題も解けるということである. ただし, このモデルでは2つの仮定を追加していることに注意する. 1つは, (3.5)には, \\(\\Phi\\)という選択肢があることだ. これは退出, つまり工場の閉鎖や事業を売却することで得られるキャッシュフローである. よって, このモデルでは採算が合わないと判断した経営者が事業撤退を選択する可能性も考慮している. もう1つは, 動学的な決定の必要があるのは\\(k_{t}\\)のみで, \\(l_{t}\\)は毎期独立して決定されるように仮定している点である.. では, \\(k_{t}\\)の動学的な意思決定がどのようになされるかを考えていく. 資本\\(k_{t}\\)は, 前期のストック\\(k_{t-1}\\)と, 減価償却率 \\(\\delta\\), そして新規の投資額 \\(\\mathit{inv}_{t-1}\\)の和で表現できる. \\[\\begin{aligned} k_{t}= &amp; \\mathit{inv}_{t-1}+(1-\\delta)k_{t-1}\\end{aligned}\\] 企業の退出ルールと投資関数を以下のように定義できる. \\(t\\)期に企業が存続するなら\\(x_{t}=1\\), そうでないなら\\(0\\)として, \\(x_{t}\\)は以下のように決定される. \\[\\begin{aligned} x_{t}= &amp; \\begin{cases} 1 &amp; \\text{if }\\omega_{t}\\geq\\underline{\\omega}_{t}(k_{t})\\\\ 0 &amp; \\text{otherwise} \\end{cases}\\end{aligned}\\] \\[\\begin{aligned} \\mathit{inv}_{t}= &amp; \\mathit{inv}_{t}(\\omega_{t},k_{t})\\end{aligned}\\tag{3.6}\\] ここから, 企業が\\(t\\)期も退出せず操業を続ける確率は \\[\\begin{aligned} p_{t}:= &amp; \\mathrm{P}(x_{t}=1\\mid\\underline{\\omega}_{t}(k_{t}))\\\\ = &amp; \\mathrm{P}(x_{t}=1\\mid k_{t},\\omega_{t},\\underline{\\omega}_{t})\\end{aligned}\\tag{3.7}\\] のように\\(k_{t},\\omega_{t},\\underline{\\omega}_{t+1}\\)の条件に依存することを覚えておこう23. 退出による利益\\(\\Phi\\)は観測できず, 別の変数で表現する必要があるため, 退出を決定するしきい値を表す関数\\(\\underline{\\omega}_{t}(\\cdot)\\)を導入する. 利潤関数\\(\\pi_{t}\\)が\\(k_{t}\\)に対して減少関数なら, 価値関数にとっては増加関数, そして資本ストックの多い企業は一時的な生産性の変化\\(\\omega_{t}\\)とはあまり関係なく, 将来に比較的大きな収益が見込まれるから, しきい値\\(\\underline{\\omega}_t(\\cdot)\\)は比較的低くなるはずなので\\(\\underline{\\omega}_{t}(\\cdot)\\)は減少関数になる(退出確率\\(p_{t}\\)の減少)はずだ. よってこの退出ルールから\\(\\omega_{t+1}\\)に\\(x_{t+1},k_{t+1},l_{t+1},\\omega_{t}\\)を条件付けた\\(\\omega_{t+1}\\)の期待値 \\[\\mathrm{E}\\left[\\omega_{t+1}\\mid k_{t+1},\\omega_{t},x_{t+1}=1\\right]\\] は\\(k_{t+1}\\)に対して減少関数であるとわかる (\\(l_{t+1}\\)は独立しているので\\(\\omega_{t+1}\\)に影響しない). これが観測できない生産性 \\(\\omega_{t}\\)と資本\\(k_{t}\\)が相関していることの理由付けになる. ここまでで登場した変数間の関係をグラフィカルモデルで描くならば, 図3.1のようになる. 図3.1: OPモデルで仮定した変数の関係 3.5 OPモデルの回帰モデルとしての意味 経営者が (分析者には) 観察されない効果\\(\\omega_{t}\\)を参照して\\(k_{t},l_{t}\\)を決めてしまうというのは, 計量経済学の文脈でいうなら欠落変数バイアスであり, ここまでで紹介したパネルデータの方法で推定してもバイアスが発生してしまう. さらに \\(\\omega_{t}\\)のマルコフ性を仮定しているため, もし\\(\\omega_{t}\\)が過去の値と相関しているならば, やはり内生性によるバイアスが発生する. また, OPモデルは経営者の撤退という選択肢も想定していることは, サンプルセレクションバイアスを考慮しているとも言える. 前節ではパネルデータには一切欠測がない(バランスドパネル)ことを暗黙の前提としていたが, 実際のパネルデータではしばしば欠測が起こる. もし欠測が企業の活動とは完全に無関係にランダムに発生している(MAR; missing at random)ならば推定に大きな影響はないが, すでに解説したように\\(k_{t}\\)は\\(\\omega_{t}\\)(の期待値)に相関し, \\(\\omega_{t}\\)の大きさ次第で企業経営者は撤退を決める. つまりモデル内の変数に依存するメカニズムで発生している(MNAR; missing not —)ことになるので推定にバイアスを引き起こす24. 推定のため, 投資を\\(\\mathit{inv}_{t}=\\mathit{inv}(k_{t},\\omega_{t})\\)という関数で表現できるとして, \\(\\mathit{inv}_{t}&gt;0\\)と仮定すると, 投資関数 \\(\\mathit{inv}_{t}(\\cdot)\\)が厳密に単調増加関数であれば25, 逆関数 \\(\\omega_{t}=h_{t}(k_{t},\\mathit{inv}_{t})\\) が存在することになる. 言い換えるなら, \\(\\mathit{inv}_{t}\\)は操作変数である. これを(3.2)に代入すると, \\[\\begin{aligned} y_{t}= &amp; \\beta_{L}l_{t}+\\left[\\beta_{A}+\\beta_{K}k_{t}+h_{t}(k_{t},\\mathit{inv}_{t})\\right]+\\varepsilon_{t}\\end{aligned}\\tag{3.8}\\] となり, 観察されない効果を他の説明変数で表現できることがわかった. \\(\\left[\\cdots\\right]\\)の部分は関数形が特定されていない, いわゆるノンパラメトリックモデルである. しかし, 今知りたいのは\\(\\beta_{A},\\beta_{K},\\beta_{L}\\)であって, 投資関数を特定することは必須でない. そこで, OP法では以下のような2段階の推定法で一致推定量を得る. 第1段階では\\(k_{t}\\)と\\(\\omega_{t}\\)という動学的に決定される部分をノンパラメトリック回帰することで, 静学的に決まる\\(\\beta_{L}\\)のみを識別する. そこで, 相関のある部分をまとめて, 以下のように \\(\\phi_{t}\\)と表す. \\[\\begin{aligned} \\phi_{t}(k_{i,t},\\mathit{inv}_{i,t}):= &amp; \\beta_{A}+\\beta_{K}k_{i,t}+h_{t}(k_{i,t},\\mathit{inv}_{i,t})\\end{aligned}\\tag{3.9}\\] \\(\\phi_{t}\\)を使うと(3.8)は以下のように書き換えられる. \\[\\begin{aligned} y_{t}= &amp; \\beta_{L}l_{t}+\\phi_{t}(k_{t},\\mathit{inv}_{t})+\\varepsilon_{t}\\end{aligned}\\tag{3.10}\\] このモデルの\\(\\phi_{t}\\)の部分をノンパラメトリック回帰で推定する26ことで, 推定値\\(\\hat{\\beta}_{L}\\), \\(\\hat{\\phi}_{t}\\)が識別された. これは別の見方をすれば部分線形モデル (partially linear —) である27. \\(\\hat{\\beta}_{L}\\)を得られたので, 当初の式は以下のように書ける. \\[\\begin{aligned} y_{t}-\\hat{\\beta}_{L}l_{t}= &amp; \\phi_{t}(k_{t},\\mathit{inv}_{t})+\\varepsilon_{t}\\end{aligned}\\tag{3.11}\\] よって残りは\\(\\omega_{t}\\)や\\(k_{t}\\)をひとまとめにした\\(\\phi_{t}\\)からどうやって\\(\\beta_{A},\\beta_{K}\\)を識別するかという問題である. ここからがOlleyらの研究の肝であり, 込み入った説明になる箇所である. \\(\\hat{\\phi}_{t}\\)には\\(\\beta_{A}+\\beta_{K}k_{t}+\\omega_{t}\\)が含まれているが, \\(k_{t}\\)は既に説明したように動学的に決定される. ここで, 次の\\(t+1\\)時点の \\(y_{t+1}-\\beta_{L}l_{t+1}\\)の期待値を考えると, \\(\\omega_{t}\\)のマルコフ性から以下のように書ける. \\[\\begin{aligned} \\mathrm{E} &amp; \\left[y_{t+1}-\\beta_{L}l_{t+1}\\mid k_{t+1},x_{t+1}=1\\right]\\\\ &amp; =\\beta_{A}+\\beta_{K}k_{t+1}+\\mathrm{E}\\left[\\omega_{t+1}\\mid\\omega_{t},x_{t+1}=1\\right]\\\\ &amp; =\\beta_{K}k_{t+1}+g(\\omega_{t},\\underline{\\omega}_{t+1})\\end{aligned}\\] ここで, \\(g(\\omega_{t},\\underline{\\omega}_{t+1})=\\beta_{A}+\\mathrm{E}\\left[\\omega_{t+1}\\mid k_{t+1},x_{t+1}=1\\right]\\)であり, 欠落バイアスを表している. \\(g\\)は観測できない\\(\\omega_{t}\\)で構成されるが, (3.7)から, \\(t+1\\)時点の存続確率\\(p_{t+1}\\)は\\((k_{t+1},\\omega_{t})\\)の関数で書けることが分かっている. さらに, 期首の\\(k_{t+1}\\)は前期の\\(k_{t},\\mathit{inv}_{t}\\)に依存する(この\\(k_{t+1}\\)は\\(\\omega_{t+1}\\)が決まる前の値なので, 経営者が投入量を決めるという話とは無関係). よって, \\(t+1\\)時点の\\(g(\\cdot)\\)は\\(p_{t+1}\\)と\\(\\omega_{t}\\)で表現できることがわかる(つまりこれは一種の傾向スコアである). 退出したかどうか(\\(x_{t}\\))はパネルデータの欠測で知ることができるため, \\(x_{t}\\) に対してプロビット回帰28をすることで確率の推定値\\(\\hat{p}_{t}\\)を計算できる. さらに, \\(\\omega_{t}\\)は, 第1段階で推定した\\(\\phi_{t}(k_{t},\\mathit{inv}_{t})=\\beta_{A}+\\beta_{K}k_{t}+\\omega_{t}\\)から, 以下のように書ける. \\[\\begin{aligned} \\hat{g}(\\omega_{t},\\underline{\\omega}_{t+1})= &amp; g(\\hat{p}_{t+1},\\hat{\\phi}_{t}-\\beta_{A}-\\beta_{K}k_{t})\\end{aligned}\\] \\(\\hat{g}\\)と\\(\\omega_{t}\\)のバイアスを\\(\\hat{\\xi}_{t+1}:=\\omega_{t+1}-\\hat{g}(\\omega_{t},\\omega_{t+1})\\)として, 当初の式(3.11)に代入できる. 第2段階29では\\(\\hat{\\beta}_{L}\\), \\(\\hat{\\phi}_{t}\\), \\(\\hat{p}_{t}\\)を所与として, 以下のようなラグのある回帰式を推定する問題として扱える30. \\[\\begin{aligned} (y_{t+1}-\\hat{\\beta}_{L}l_{t+1})= &amp; \\beta_{K}k_{t+1}+g(\\hat{p}_{t},\\hat{\\phi}_{t}-\\beta_{A}-\\beta_{K}k_{t})+\\hat{\\xi}_{t+1}+\\varepsilon_{t+1}\\end{aligned}\\tag{3.12}\\] (プロビットモデルの推定がバイアスなくできているならば)\\(\\hat{\\xi}_{t+1}\\)は平均ゼロでかつ\\(k_{t+1}\\)とも独立だが, \\(l_{t+1}\\)とは相関しているかもしれない. しかし\\(\\beta_{L}\\)は第1段階で推定した\\(\\hat{\\beta}_{L}\\)を代入できるため, もはや気にする必要はない. \\((\\hat{\\xi}_{t+1}+\\varepsilon_{t+1})\\)を誤差項とみなすと, \\(\\beta_{K}\\)は誤差項と相関しないので識別できる. そして\\(g(\\cdot)\\)は構造がわからない非線形関数である. そこで, Olleyらは2通りの推定方法を試している. 1つは1段階目と同様に部分線形モデルとしてカーネル回帰を利用する方法, もう1つは, 多項式近似した上で非線形最小二乗法で解く方法である. つまり, \\[\\begin{aligned} y_{t+1}-\\hat{\\beta}_{L}l_{t+1}= &amp; \\beta_{K}k_{t+1}+\\sum_{d=1}^{q}\\sum_{m=0}^{d}\\gamma_{m,d-m}\\hat{h}_{t}^{m}\\hat{p}_{t}^{d-m}+(\\hat{\\xi}_{t+1}+\\varepsilon_{t+1})\\end{aligned}\\] である. ここで, \\(\\hat{h}_{t}:=\\hat{\\phi}_{t}-\\beta_{A}-\\beta_{K}k_{t}\\)で, \\(q\\)は多項式の次数である. なお, OP法では標準誤差を代数的に得られないため, ブートストラップシミュレーションで計算する必要がある. この方法で導出したモデルの統計的性質は Pakes and Olley (1995) でより詳しく説明されている. 3.6 モデルの事後診断 さて, 反事実分析でのモデルの評価は単に当てはまりが良いかだけでなく, 仮定と現実のデータが矛盾していないかの確認も同等かそれ以上に重要である. ここでもOlleyらの研究を例にする. まず, 彼らの仮定が正しければ, 単なる最小二乗法や, IVなどの方法では結果にバイアスが発生するはずである. よって, 提案する推定方法との比較が必要である. あるいは, サンプルセレクションバイアスが実際に発生しているか確認するため, バランスドパネルでの結果と比較することも必要である. さらに, 市場の構造は法規制の変化によって変わりうる. 法改正のタイミングで年代ごとに区切って当てはまりを確認する必要がある. さらに, モデルのロバストネス分析として, モデルの仮定のうち特に重要な, 投資関数の式(3.6)を検討している. 投資が資本と観察できない生産性によって決まるという仮定が正しくない場合, \\(\\beta_{L}\\)の推定にバイアスが生じる. これを検証するには最後の式(3.12)の説明変数に, 現在の\\(l_{t}\\)を加えることでできる (このようなタイプの検証は特定化のテストと呼ばれる). 3.7 OP法以降の研究 Levinsohn and Petrin (2003) はOP法を改良した方法を提案している. 多くの企業の会計情報を見ると, 実際には設備投資は必ずしも発生せず, ゼロが多い. これは投資関数の単調性と矛盾するため, 中間投入財 (材料費) の情報を利用することを提案している. 現在はさらに Ackerberg, Caves, and Frazer (2015) が改良版を提案して, これがスタンダードになりつつあるらしいが今回は省略. References "],
["r-での実装.html", "4 R での実装 4.1 データのとり方 4.2 \\(\\beta_{L},\\phi\\)の識別 4.3 存続確率の推定 4.4 \\(\\beta_{A},\\beta_{K}\\)の推定", " 4 R での実装 4.1 データのとり方 企業の生産関数推定で一番むずかしいのは実はここかもしれない. というのも, 理論上の\\(K\\)や\\(L\\)はどこにも記載されていないからだ. これはけっこう地道な計算が必要になる. 例えば企業の決算報告書などから地道に計算する, あるいは日銀やDBJのような政策金融機関が整備しているデータベースをなんらかの手段で見せてもらう, などである. あるいは, 農業や工業など資源と生産物の関係が分かりやすい特定の産業だけでを分析の対象とすることもできる. 例えば農業で, \\(K\\)を乳牛の頭数, 原材料を飼料, \\(Y\\)をミルクの生産量とした分析も可能だろう (昔見た気がするがすぐには見つけられなかった). 今回はとてもそんなことをしている暇も金もコネもない31ので, 後述する乱数データを使う. estprodパッケージが, Olley-PakesやLevinsohn-Petrinの方法を実装したという. さらに, このパッケージには練習用の乱数データセットも用意されている. この乱数がどのような方法で生成されたかがわからないので, 実質的に動作確認にしかならないが, まずはこれを使ってみた. しかし, 1段階目の推定を検証してみたところ, 残差プロットの形がかなり変になった. 残差プロットが必ず完璧な45度線を引かなけばならない, ということはないが, データの生成方法は分からないこともあって用例として不安である32. よって, Kawaguchi (2019) の課題2に沿って疑似データを生成してやり直すことにした. しかし, 去年の講義内容とはいえ課題の答案を勝手に一般公開してしまうのも無配慮すぎる気がするため, 乱数データを作成するプログラムは非公開として, 当初の課題から乱数シード値などを変更して作成したデータdf_sample, df_ground_truthのみ公開する. 前者は標本データで, 後者は\\(\\omega_{t},p_{t}\\)など本来は観測できない変数も見えるようにしたデータである(表4.1, 以下, 後者を「正解データ」と呼ぶ). 以降はこのdf_sampleを使ってパラメータを推定する. 推定したい3つのパラメータは元の課題どおり, \\(\\beta_{A}=1,\\beta_{K}=0.7,\\beta_{L}=0.2\\)としている. 表4.1: 乱数データの変数対応表 i t k k_lag inv inv_lag x y y_true omega p_x 標本 企業ID \\(t\\) \\(k_{t}\\) \\(k_{t-1}\\) \\(\\mathit{inv}_{t}\\) \\(\\mathit{inv}_{t-1}\\) \\(x_{t}\\) \\(y_{t}\\) NA NA NA 正解データ 企業ID \\(t\\) \\(k_{t}\\) \\(k_{t-1}\\) \\(\\mathit{inv}_{t}\\) \\(\\mathit{inv}_{t-1}\\) \\(x_{t}\\) \\(y_{t}\\) 退出しない場合の\\(y_{t}\\) \\(\\omega_{t}\\) \\(p_{t}\\) なお, 乱数生成したため, 偶然にも一部の企業が全期間で退出している. データとして不自然だが計算には問題ないので修正せずそのままにしている. 4.2 \\(\\beta_{L},\\phi\\)の識別 1段階目の推定は部分線形カーネル回帰で推定する. これはnpパッケージで提供されている. 今回はnpplregbw()でデータから最適バンド幅を決定し, 決定したバンド幅をnpplreg()に与えて推定する3334. この推定結果を残差プロット等で確認したら, \\(p_{t}\\)の推定を行う. 1段階目のモデル(3.10)は, 誤差項と相関のある部分線形モデルであり, 単に多項式やスプライン近似を適用しただけでは正しく\\(\\phi\\)を推定できないため, npplregbw(formula = y ~ l k + inv)としても誤差項の相関のために\\(\\beta_{L}\\)は正しく推定されず, 全く異なる値になる. そこで部分線形モデルとコントロール関数アプローチの併用によって\\(\\beta_{L},\\phi\\)を識別する. このためには, formula = y ~ l + k | k + inv と指定する. これで, \\(\\beta_{L},\\phi\\)を識別できるが, もちろんこの時点では \\(\\beta_{K}\\)は正しく推定できていない. # somehow `na.action` doesn&#39;t work so we need `drop_na()` bw_1st &lt;- npplregbw(formula = y ~ l | k + inv, data = df_sample %&gt;% drop_na(y, k, l, inv)) fit_1st_np &lt;- npplreg(bw_1st) summary(fit_1st_np) なお, npパッケージのノンパラメトリック回帰は計算負荷がけっこうある. そこで, 面倒だったらOlleyらと同様に以下のような多項式近似でごまかしても良い. lm(y ~ l + poly(k, inv, degree = q), data = df_sample) degree = q は多項式の次数で, formulaを評価する際には\\(\\sum_{r\\leq q}k_{t}^{r}\\mathit{inv}_{t}^{q-r}\\) と認識される. 何も考えずに degree = 4 としてもそこそこそれらしい値を推定できるが35, Olleyのやるように推定値とMSEが安定する次数を選ぶのがスマートだろう. しかし残念ながら stats::step() 関数には poly() の次数を調整する機能がないので, ループ処理か予め決めた次数までを並列処理して比較する必要がある. そこで, 以下のように10次までの多項式あてはめを一度に実行する処理を書いた36. set.seed(42) df_fit_1st_poly &lt;- tibble(q= 1:10) %&gt;% mutate(model = map(q, function(q){ if(q == 1){ poly_term &lt;- &quot;+ k&quot; } else{ poly_term &lt;- paste(&quot;+ poly(k, inv, degree =&quot;, q, &quot;)&quot;) } lm(as.formula(paste(&quot;y ~ 1 + l + k&quot;, poly_term )), data = df_sample) })) %&gt;% mutate( rmse = map_dbl(model, function(x) sqrt(mean(x$residuals^2))), coef = map(model, function(x) enframe(coef(x)) %&gt;% filter(name %in% c(&quot;k&quot;, &quot;l&quot;))) ) %&gt;% unnest(coef) %&gt;% pivot_wider(names_from = name, values_from = value) # we select 5th order, the estimate of beta_l = .161 fit_1st_poly &lt;- df_fit_1st_poly$model[[5]] ところで, 現在はノンパラメトリックな回帰モデルとしてスプライン回帰の研究が進んでいる(基本的な事項は Hastie, Tibshriani, and Friedman (2009), Ch. 5), 坂本, 井筒, and 白旗 (2009) などを参照). スプライン回帰にもバリエーションがあるが, 典型的なものは区間ごとに異なる次数の多項式で表現するため, 単純な多項式近似よりも表現の自由度の高い非線形近似の方法である. さらにSemiPar::spm()は部分線形モデルに対しても罰則付き最尤推定という方法で当てはめたスプライン回帰を計算することができる. 表現の自由度で言えばカーネル回帰のほうがさらに優れているが, 計算時間はこちらのほうが少ない. 多項式近似である程度うまくいくのだからスプライン回帰でもうまくいくと思ったのだが, なぜかうまく行かない. 原因を調べるのがめんどくさくなったので読者の課題とする. tmp &lt;- select(df_sample, y, k, l, inv) f_spm &lt;- spm(form = tmp$y ~ tmp$l + f(tmp$k, tmp$inv), omit.missing = T) summary(f_spm) 4.3 存続確率の推定 Olleyは, 理論モデルの仮定から\\(p_{t+1}\\)を決定する関数は\\(k_{t},\\mathit{inv}_{t}\\)の2変数関数で表現できることから, この2変数を使ったプロビットモデル(ロジットリンク関数を標準正規分布に置き換えたもの)と多項式近似またはカーネル回帰を組み合わせて確率を推定している. 今回は正解が分かっているため, \\(p_{t+1}\\)と\\(k_{t},\\mathit{inv}_{t}\\)の関係を知ることができる. 2変数の散布図とカーネル回帰で近似曲線を当てはめたものが以下のようになる. プロビットモデルならば, \\(p_{t+1}\\)を標準正規分布の逆分布関数 (分位点関数)で変換した値と説明変数が線形相関していれば, その説明変数を使うことで当てはまりの良いモデルができると予想できる. しかし, 図4.1からわかるように, 2つの説明変数との相関関係はいずれもあまり直線的でないことがわかる. 図4.1: 真の確率と説明変数の相関 よって, 単なる一般化線形回帰ではなく, より複雑な非線形近似方法を使う必要があるとわかる. Rでは多項式プロビット回帰はglm()とpoly()の組み合わせで, 例えば以下のようにして計算できる. ここでも次数をデータの当てはまりで決定するため\\(\\beta_L\\)の推定と同様に次数を変えて並列処理している. 1段階目で使用したnpパッケージは線形回帰のみ対応しているため, プロビットモデルの推定はできない. 他のRのパッケージでは, 例えば各変数をスプライン補間などで非線形変換した一般化加法的モデル (GAM37)を計算できるmgcvパッケージ, 一般化ガウシアンカーネル回帰のできるbkmrパッケージや, 一般化部分線形モデルを計算できるgplmなどがある. これらはいずれもノンパラメトリックあるいはセミパラメトリックなモデルと呼ばれるが, それぞれ表現方法が違うため, 当てはまりの良さも変わってくる38. また, このパートではそもそも係数の推定が不要なので, 確率さえ推定できているならランダムフォレストのような自由度の高いモデルでも問題ないだろう39. 今回はmgcv, bkmr, gplm, rangerなどを使って推定してみた. なおKawaguchiの課題では退出行動を省略しているのでこのパートは存在しない. 4.4 \\(\\beta_{A},\\beta_{K}\\)の推定 最後の推定は, \\(\\omega_{t}\\)を推定し, さらに企業の退出行動によるサンプルセレクションバイアスを補正するための計算である. まず, 計算の無駄をなくすためにの関数のように推定に必要なラグ項をデータフレーム側で作成しておく. mutate()関数内でdplyr::lag()を使えばそれぞれのラグ項を得られる40. 元のパネルデータをdf_sample, 1段階目の推定結果をfit_1stとして, 2段階目の推定のためのデータセットdf_sample_2ndを作成している. y_bl, phi, p_x はそれぞれ\\(y_{t}-\\hat{\\beta}_{L}l_{t},\\hat{\\phi}_{t},p_{t}\\)に対応する. make_2nd_sample &lt;- function(data, beta_l, phi, p_x){ data %&gt;% mutate( bl = l * beta_l * l, y_bl = y - bl, phi = phi, p_x = p_x ) %&gt;% arrange(i, t) %&gt;% group_by(i) %&gt;% mutate( phi_lag = lag(phi), ) %&gt;% ungroup } ここで一旦, 実際には観測できない \\(\\beta_{L},\\omega_{t}\\)の情報を使って\\(\\beta_{K}\\)を正しく推定できることを確認してみる. 以下のように\\(y_{t}-\\beta_{L}l_{t}-\\omega_{t}\\)に対して線形回帰をした結果, \\(\\beta_{A}=1.00,\\beta_{K}=0.70\\)とほぼ正確な値が出ている. lm(formula = y_bl - omega ~ k, data = df_ground_truth_2nd) %&gt;% summary() Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 0.851 0.008 112.044 0 k 0.700 0.008 88.000 0 しかし, 実際には\\(\\omega_{t}\\)は不明であり, 1段階目で推定した\\(h_{t}\\)と確率\\(p_{t}\\)から推定する41. Olleyらの方法と同様に多項式近似による非線形最小二乗法で計算する. なお再び正解データを覗き見すると, \\(\\hat{\\phi}_{t},\\hat{p}_{t+1}\\)と\\(\\omega_{t+1}\\)の関係はそれぞれ図4.2のようになっている. 図4.2: \\(\\hat{\\phi}_{t},\\hat{p}_{t+1}\\)と\\(\\omega_{t+1}\\)の正解データとの相関関係 非線形最小二乗法の計算はstats::nls()関数が提供されており, この関数はformulaで記述できたり, lm()のように標準誤差を計算してくれたりする. しかし今回は多項式部分をformulaで記述するのがやや面倒なのと, nls()の計算する標準誤差が意味をなさないため, optim()関数で計算する. 目的関数は以下のように, 任意の次数の(3.12)のMSEを計算できるような関数を作った. \\(p_{t},h_{t}\\)の交差項を含む\\(q\\)次多項式の第\\(d\\)次項は\\(d+1\\)個存在するため, 1次から\\(d-1\\)次までの項の総数は\\(\\sum_{i=1}^{d}i\\), 項の総数は\\(\\sum_{d=1}^{q}(d+1)\\)個であるから, 上記のようにpurrr::map_dfc(), purrr::reduce()を入れ子にして計算した42. なお, 数値計算上の観点から初期値にも注意する必要がある. これは補遺Aで詳しく説明している. また, Olleyらはさらにここでもカーネル回帰も試しているが, パラメータが含まれる非線形式のカーネル回帰は自分で1から書かなければならず面倒になったので今回は省略する. そして標準誤差を代わりに (ノンパラメトリック) ブートストラップ法で計算する. ブートストラップ法による標準誤差の計算方法は補遺Bで補足説明している. 以上で説明した内容は, Githubリポジトリのall_public.Rにまとめてある. References "],
["結果.html", "5 結果", " 5 結果 FE, RDなどの内生性を想定しないパネルデータの方法と, Arellano-Bondの階差GMMなどの動学パネルデータモデル, OPの方法, そしてCで詳しく紹介するKawaguchiの課題での方法のそれぞれの推定結果を図5.1に示す43. OPの方法は, 多項式回帰とカーネル回帰の両方を試したいところだが, カーネル回帰は既存のパッケージを使いまわせず実装にも時間がかかるので省略した. また, 確率推定をGAMやランダムフォレストに置き換えたケースについても, 結果にほとんど違いがなかったため省略した. Kawaguchiの課題では一般化モーメント法(GMM)で計算しており, その条件の特定は今回のデータとも合致しているが退出行動を省略しているためバイアスが発生することが予想できる(やる気があれば本来の課題との結果の違いを比較すると面白いだろう). 図5.1: 推定結果 それ以外の方法については, 推定された係数のバイアス(真値との差)のみ一覧表を掲載する5.1 表5.1: 各推定のバイアス Model beta[A] beta[K] beta[L] OP_poly -0.250 -0.046 0.206 OP_GAM -0.244 -0.047 0.200 OP_RF -0.242 0.032 0.130 OLS -0.100 0.794 -0.696 Within 1.335 0.791 -0.746 Between -0.103 0.791 -0.690 Twoway 1.331 0.792 -0.741 FD -0.999 0.780 -0.804 RE -0.100 0.794 -0.696 AB_twoway 1.440 0.840 -0.833 AB_indivi 1.550 0.818 -0.987 BB_twoway 1.508 0.823 -0.931 BB_indivi 6.133 1.119 -6.326 GMM (Kawaguchi) 0.079 0.038 -0.311 estprod`はOP法の実装といいつつ企業の途中退出を考慮していない上, 退出のないデータに当てはめても全く違う結果が帰ってきたのでなかったことにした. また, 今回書いたOP法の各バリエーションは結果がほとんど変わらなかったため多項式の場合のみを代表して掲載し, AB/BB推定量はあまりにも誤差が大きいため掲載を省略した.↩ "],
["まとめ.html", "6 まとめ", " 6 まとめ 今回は, 因果推論と呼ばれるRubin的な介入効果の推定メソッドが経済学では誘導形と呼ばれること, そして誘導形と対比される形で構造推定と呼ばれる方法論が存在することを説明した. 今回具体例として取り上げたOlleyとPakesの研究は, 変数の内生性によって, 動学パネルデータや個別効果モデルといった従来の推定方法では生産関数を適切に推定できないことを指摘した上で, 経済モデルを想定した推定方法によってパラメータを識別したというものである. そして, 提案される計算手順をRでデモンストレートした. 今回は取り掛かった段階で準備期間が1週間を切っていたため, かなり手を抜かざるを得なかった. 以前の発表の続編ということで, 動学構造推定をRで実演したかったのだが, まず説明を書くのに時間がかかるので, 静学構造推定に, そしてRのプログラムを用意する時間もなくなってきたので実装もなし, となし崩し的に縮退していった. さらには, タイトルで「反事実分析」と書いたわりに「反事実」的な要素のあまりない研究を挙げることになってしまった. 今回挙げたOlley-Pakes や Levinsohn-Petrinの研究は10年以上前の話なので, すでに大学院, あるいは学部の授業でも取り上げられることすらあるようだ. そういう意味でもあまりおもしろみのない発表だったとは思う. しかし, 実際に乱数データでOP法本来のやり方を試してみると, 簡単な生成ルールであっても初期値に依存して標準誤差が大きくなるなど, 意外と扱いづらいことがわかった. これは再現性の問題にも関わってくると思うので, より安定した推定方法を議論するのもおもしろいかもしれない. "],
["init.html", "A 数値計算上に関係する実装上の注意", " A 数値計算上に関係する実装上の注意 非線形最小二乗法は一般に解が一意とは限らない. では\\(h_{t}:=\\hat{\\phi}_{t}-\\beta_{K}k_{t}\\)として計算しており, \\(\\beta_{A}\\)を除いていない. この方法では \\(\\beta_{A},\\omega_{t}\\)を識別できないからである(Olleyらの目的はTFPの計算なので, \\(\\beta_{K},\\beta_{L}\\)さえ識別できれば問題にならない). 例えば\\(\\mathrm{E}\\omega_{t}=0\\)と分かっているならば識別できるが, 今回の仮定ではそれはわからないため, 数値計算の安定のために\\(\\beta_{A}\\)の減算を省略している. また, 非線形最適化は初期値を変えると結果が大きく変わることがある. 一般的な解決方法はないが, 今回は生産関数の意味から考えて \\(0&lt;\\beta_{K}\\)という制約を与えている. もし\\(\\beta_{K}\\)がゼロや負なら, 資本投入量を増やしてもまったく生産量が増えないか, むしろ減少することになる. これは通常ならありえないことだろう. optim()関数には lowerというオプションがあるが, ここでは計算速度を損なわないように \\(\\beta_{K}\\)のみ指数変換して計算するように修正している さらに, 初期値を\\(1-\\hat{\\beta}_{L}\\)とした. これは, \\(\\beta_{K}+\\beta_{L}=1\\)ならば生産関数が規模に対して収穫一定になるからである. もちろんそのようになるという仮定をしていないが, 生産関数のパラメータが極端な値にならないという前提ならば中庸な設定であり, 初期値に向いていると考えられる. この初期値に乱数でばらつきを与えて複数回の結果を確認すると, 初期値と収束した解の対応関係は図A.1のようになり, 次数\\(q\\)ごとの誤差\\(\\pm\\sigma\\)は図A.2のようになった. このように, \\(\\beta_{K}\\)は初期値によって結果にばらつきがあり, \\(\\beta_{A}\\)は初期値に完全に依存していることがわかる. そのため,今回は各次数について100回試行し, 平均値から次数を決定し, その後再びブートストラップ法で反復計算した結果を最終的な推定値として採用することにした. 図A.1: 解の初期値と収束先 図A.2: 次数ごとの初期値の違いによる誤差 また, 乱数データを生成するパラメータを変更すれば当てはまり易さも変わってくることに注意する. 例えば \\(p_{t}\\)の推定には\\(\\mathit{inv},k_{t}\\)を使用しているが, もしこれらと\\(x_{t}\\)との相関が弱ければ, 弱相関操作変数と同様にかえってバリアンスが増加する原因になると予想できるため, 企業のデータを取れば常にOP法をそのまま適用すればいいということはありえないだろう. このような観点からも構造推定は決まったパッケージの決まった構文を実行すれば終わりというものではなく, 各段階で仮説が正しいかを検証する必要がある. "],
["boot.html", "B ブートストラップ標準誤差", " B ブートストラップ標準誤差 Efron (1979, Bootstrap Methods: Another Look at the Jackknife)は再標本化によって標準誤差や分布の分位点を推定する方法をいくつも提案し, これらをブートストラップ法と総称した. ブートストラップ法はパラメトリックなものとノンパラメトリックなものに大別されるが, 今回はノンパラメトリックなブートストラップ法を利用する. 最も単純なブートストラップ法は次の通り44. \\(N\\)件のデータ\\(\\mathcal{D}=\\{z_{1},\\cdots,z_{N}\\}\\)を取得できたとして, ここから復元抽出した\\(N\\)件の標本(ブートストラップ標本)を\\(B\\)個作成する. \\[\\begin{aligned} D_{1}= &amp; \\{z_{1}^{(1)},\\cdots,z_{N}^{(1)}\\},\\\\ \\vdots\\\\ D_{B}= &amp; \\{z_{1}^{(B)},\\cdots,z_{N}^{(B)}\\}\\end{aligned}\\] もし, この擬似的に作られたブートストラップ標本\\(D_{b}\\)が母集団から無作為抽出された標本と同等の分布に従うならば, それぞれの標本平均\\(\\bar{z}^{(b)}\\)はすべて同一の分布にしたがう. よって, 以下のように計算した標本標準偏差を標準誤差の推定値とすることができる. \\[\\begin{aligned} \\hat{\\mathit{SE}}(\\bar{z}):= &amp; \\sqrt{\\frac{1}{B}\\sum_{b=1}^{B}(\\bar{z}^{(b)}-\\bar{z}_{B})^{2}},\\\\ \\bar{z}_{B}:= &amp; \\frac{1}{B}\\sum_{b=1}^{B}\\bar{z}^{(b)}\\end{aligned}\\] これが標本平均でなく回帰分析の係数に置き換わっても同じことが言える. つまり今回のOP法のように推定量の分布を解析的に導出するのが難しい場合にブートストラップ法を利用する場面がある. しかし, 「ブートストラップ標本が母集団から無作為抽出された標本と同等の分布に従う」という前提を忘れてはならない. 上記の単純なケースではどの標本も等確率に抽出されており, 言い換えるなら母集団の分布がそのようになっていると暗黙に仮定していることになる. Efron (1979, Bootstrap Methods: Another Look at the Jackknife)は, 推定した回帰モデルの残差から誤差項の経験分布を構成し, これを誤差項\\(\\varepsilon\\)の分布とみなしてサンプリングした乱数\\(\\hat{\\varepsilon}_{i}^{\\ast}\\)とモデルの予測値の和 \\[\\hat{y}_{t}^{\\ast}:=\\hat{y}_{t}+\\hat{\\varepsilon}_{t}^{\\ast}\\] を生成することを提案している. 標本からの計算のため, 大数の法則や中心極限定理からの類推で直観的に\\(B\\)が大きいほど推定の精度がよくなると予想できる. しかしながら, 具体的にどれくらいなら十分であるかを示す理論は存在しないようだ. ネット上では具体的な数字を挙げる例も見られるが, 具体的な根拠は挙げられていないことが多い45. これに関しては Rule of thumb for number of bootstrap samples - Cross Validated のAdamOの回答が参考になる. いわく, 十分な回数は問題に応じて変わる(例えばコーシー分布に従うデータならば何万, 何千万回やろうとそも存在しない平均を求めるのに十分ではない)ため, ブートストラップ計算の結果をヒストグラムに表し分布が適切な形になっているかを確認せよ, ということである. とはいえ, 彼の回答の追加コメントでも指摘されるように, 多くの場合は回数が多いほど精度が増すはずなので, 例えば先行研究と比較できるようにいったん同じ回数で計算した上でヒストグラムを確認し, もしうまくいってないなら回数を増やす (またはバグを疑う), といった方法が現実的ではないかと考える. ブートストラップ法の計算に関するRのパッケージはsimplebootとbootパッケージの2つが代表的である46.simplebootは名前の通り簡単なブートストラップ法の計算だけに限定したパッケージで, OP法のような特殊なモデルには対応していないからboot::boot()を使う. ただし, npパッケージによるカーネルベースの推定方法はただでさえ時間がかかるため, 今回は1段階目を多項式近似でやることにした. boot()の使い方はパッケージのヘルプを見ればすぐ分かるが, 一応簡単に解説しておく. 第1引数dataにデータを, 第2引数statisticに計算したい統計量(のベクトル)を返す関数を与える. boot()はdataをリサンプリングしてブートストラップ標本を作り, それぞれをstatisticに与えてブートストラップ推定値を計算する. statisticに与える関数の第1引数にはdataが, 第2引数には生成ブートストラップ標本がdataのどこかを表すインデックスベクトルが与えられる. さらに関数ヘルプには補外データに対してブートストラップ法を適用する例が掲載されている. この場合, 予測値の計算にももう1つインデックスベクトルが必要になる. これが第3引数である. 第4引数以降は, ユーザーが自由に定義できる引数である. そのため, 既に書いたように回帰モデルに対してノンパラメトリックブートストラップ法を適用する場合は, 予め残差を計算して入力データに含めておく必要がある. 今回はのように書いた. 回帰モデルのブートストラップ統計量の計算のため, dataには通常の推定に必要な変数に加え, ブートストラップ標本を生成するための\\(\\hat{y}_{i,t},\\hat{\\varepsilon}_{i,t}\\)の列を追加する必要がある. 今回statisticが出力すべき統計量は3つの係数パラメータ\\(\\beta_{A},\\beta_{K},\\beta_{L}\\)だが, 確認のため各段階で推定したモデルの当てはまりについても出力するようにしている47. op_params_poly &lt;- list(beta_k = exp(fit_2nd_poly$par[2]), beta_l = unname(coef(fit_1st_poly)[&quot;l&quot;])) estimate_op_ordinary &lt;- function(data, degree_1, degree_p, degree_2nd){ fit_1st &lt;- lm(y ~ l + poly(k, inv, degree = degree_1), data = data, na.action = na.omit) beta_l &lt;- unname(coef(fit_1st)[&quot;l&quot;]) rmse_1st &lt;- sqrt(mean(resid(fit_1st)^2)) fit_exit &lt;- glm(x ~ l + poly(k_lag, inv_lag, degree = degree_p), data = data %&gt;% drop_na(k_lag, inv_lag), family = binomial(link = &quot;probit&quot;)) std_Brier &lt;- std_Brier(fit_exit$data$x, fitted(fit_exit)) df_2nd &lt;- make_2nd_sample( data, beta_l, phi = predict(fit_1st, newdata = data) - beta_l * data$l, p_x = predict(fit_exit, newdata = data, type = &quot;response&quot;) ) fit_2nd &lt;- optim( par = c(rnorm(n = 1, sd = .5), log(ifelse(1 - beta_l &lt;=0, .5, 1 -beta_l)) + rnorm(n = 1, sd = .3), rnorm(n = sum(1:degree_2nd + 1), sd = .5)), fn = obj_op_2nd, data = df_2nd, degree = degree_2nd) beta_a &lt;- mean(with(df_2nd, y_bl - exp(fit_2nd$par[2]) * k), na.rm = T) return(c(beta_a = beta_a, beta_l = beta_l, beta_k = unname(exp(fit_2nd$par[2])), rmse_1st = rmse_1st, std_Brier = std_Brier, rmse_2nd = sqrt(fit_2nd$value))) } get_stat_boot &lt;- function(data, indices, indices_, estimate, params){ # estimate = estimate function # params = model hyper parameter (e.g., degrees of polynomials) data$y &lt;- with(data, fitted + resid[indices]) do.call(estimate, args = c(list(data = data), params)) } boot_ordinary &lt;- df_sample_2nd_poly %&gt;% mutate(., fitted = if_else(is.na(y), NA_real_, do.call(get_fitted, args = c(list(data = .), op_params_poly))), resid = y - fitted) %&gt;% boot(., get_stat_boot, R = 100, strata = .$x, estimate = estimate_op_ordinary, params = list(degree_1 = 3, degree_p = 2, degree_2nd = 2)) なお, 既に書いたようにOP法では\\(\\beta_{A}\\)を識別できないが, 他の方法との比較のため\\(\\hat{\\beta}_{A}:=(NT)^{-1}\\sum_{i,t}(y_{i,t}-\\hat{\\beta}_{L}l_{i,t}-\\hat{\\beta}_{K}k_{i,t})\\)として計算した. これは本来の仮定に加えて\\(\\mathrm{E}\\omega_{t}=0\\)が成り立ってなければ適切な推定量とは言えないが, 今回の乱数データでは\\(\\omega_{t}\\)が平均ゼロの定常分布に収束するような方法で生成している. 引数Rはブートストラップ標本の生成数である. 本文での解説に沿って100に設定し, 各パラメータのヒストグラムが不自然でないか確認した. strataは層別抽出をするためのインデックスである. 今回は\\(y_{t}\\)に欠損があり, OP法は欠損していないデータだけで推定しているから, ブートストラップ標本\\(\\hat{y}_{t}^{\\ast}\\)も本来のデータの欠損メカニズムを再現する必要がある. ここではstrataに元のデータの欠損判定\\(x_{t}\\)を与えることでこれを表現している48. また, boot.ci()でboot()の結果から信頼区間を計算できるが, 今回は利用しない. 例えば標準誤差の計算なら100程度, 分位点の計算なら1000程度, という記述がよく見られる. この数値の根拠は Efron (1979) の論文に掲載されている実験でそのように設定されていたからではないかと思う. しかしEfronはこの数字の根拠を述べていない.↩ 金明哲『Rとブートストラップ』と奥村晴彦『ブートストラップ』はいずれもこれらのRパッケージを使った計算方法も含めて言及している. 『ブートストラップのためのbootパッケージ』にもbootパッケージの言及がある.↩ サンプルプログラムでは返り値に名前を付けているが, boot()は名前の情報を保存してくれないようだ↩ 欠損値を含む場合のブートストラップ法に詳しくないが, \\(y_{t}\\)に対して\\(x_{t}\\)は先決(predetermined)変数だから, 単純に\\(x_{t}\\)の層化で欠損を条件付けるだけで十分だと思う.↩ "],
["kawaguchi-gmm.html", "C kawaguchiの課題についての補足 C.1 gmmパッケージの解説", " C kawaguchiの課題についての補足 Olleyらの方法に倣えば非線形最小二乗法として係数\\(\\beta_{A},\\beta_{K}\\)を求める必要があるが, 課題では退出行動を省略し, \\(\\omega_{t}\\)の構造もシンプルなためOlleyらのような複雑な式の導出はなく, 非線形一般化モーメント法 (非線形GMM)で推定することを課している. GMMの解説はすくなく, 非線形GMMとなるとなおさらなので49, ここで少し脱線して課題では何をやっているのかを書いておく. 練習用データは\\(\\omega_{t}\\)をAR(1)過程の乱数として生成しているので, 課題では係数\\(\\alpha\\)は未知であるもののAR(1)であることは分かっているという前提である. つまり, 以下のように仮定している50ので, \\[\\begin{aligned} h(\\omega_{t+1})= &amp; \\alpha\\omega_{t}+\\nu_{t},\\\\ \\nu_{t}\\sim &amp; \\mathcal{N}(0,\\sigma_{\\nu}^{2})\\forall t\\end{aligned}\\] \\[\\begin{aligned} \\hat{\\xi}_{t+1}:= &amp; \\omega_{t+1}-\\alpha\\left(\\hat{\\phi}(k_{t},\\mathit{inv}_{t})-\\beta_{A}-\\beta_{K}k_{t+1}\\right)\\end{aligned}\\] とすると, \\[\\begin{aligned} y_{t+1}= &amp; \\beta_{L}l_{t+1}+\\beta_{A}+\\beta_{K}k_{t+1}+\\alpha\\left(\\hat{\\phi}(k_{t},\\mathit{inv}_{t})-\\beta_{A}-\\beta_{K}k_{t+1}\\right)+\\hat{\\xi}_{t+1}+\\varepsilon_{t+1}\\end{aligned}\\] となり, これを変形すると以下のようになる. \\[\\begin{aligned} \\hat{\\xi}_{t+1}+\\varepsilon_{t+1}= &amp; y_{t+1}-\\hat{\\beta}_{L}l_{t+1}-\\beta_{A}-\\beta_{K}k_{t+1}-\\alpha\\left(\\hat{\\phi}(k_{t},\\mathit{inv}_{t})-\\beta_{A}-\\beta_{K}k_{t+1}\\right)\\end{aligned}\\] 既に書いた仮定では \\(\\hat{\\xi}_{t+1}+\\varepsilon_{t+1}\\)は同時点のいくつかの変数と相関する可能性が残るが同時点の\\(k_{t+1}\\)および1時点前の\\(k_{t},\\mathit{inv}_{i,t}\\)と無相関なので以下のようなモーメント条件が成り立つ. \\[\\begin{aligned} \\mathrm{E}(\\hat{\\xi}_{t+1}+\\varepsilon_{t+1})\\begin{bmatrix}k_{t+1}\\\\ k_{t}\\\\ \\mathit{inv}_{t} \\end{bmatrix}= &amp; \\mathbf{0}\\end{aligned}\\] \\(\\hat{\\xi}_{t}+\\varepsilon_{t}\\)にはパラメータに対して非線形な項が含まれるので非線形モデルということになる. 線形モデルの場合は単にGMMと呼ばれ, 今回のような非線形モーメント条件を特定した場合を非線形GMMと呼び, ニュートン法などの非線形最適化の方法で計算することになる. なお計算には新たに\\(y_{t}-\\hat{\\beta}_{L}l_{t}\\),\\(\\hat{\\phi}_{t}\\), \\(k_{t},\\mathit{inv}_{t}\\)のラグ項が必要になるが, これらは既にで作成している. RでGMM推定法を計算するパッケージには gmm, plmがある51. 後者のplmはGMMだけでなく, FE/REモデルなどパネルデータを想定したモデルの計算用関数が用意されている. 今回もパネルデータを利用しているが, 個別効果を想定していないためplmを必ず使わなければならないわけではない. 実際のところ, plm::pgmm()でできるGMMは既に少しだけ言及したArellano-Bond/Blundell-Bondの動学パネルデータモデルの推定だけであるので, 今回のような非線形GMMには使えない. 一方でgmmパッケージは非線形GMMにも対応しているので, 今回はこちらを使う. また, GMMを使う場合も標準誤差はブートストラップ法で計算する必要がある. しかしカーネル回帰は非常に時間がかかるため, 100回も1000回も繰り返すのは現実的ではない. 今回時間がかかるのは主に最適バンド幅を計算するnpplregbw()の実行なので, 最初の計算で得たバンド幅を全てのブートストラップ標本で共用することにした. しかし, npパッケージは引数に対する挙動がかなり意味不明で混乱を招く. 所与のバンド幅でデータを変えて再計算したい場合の方法が不明瞭である. いろいろ試したが, dataに与えるだけではバンド幅計算時の結果がそのまま出力されるようだ. txdat, tydat, tzdatにそれぞれ新しい数値を与える必要があるらしい. npplreg(bws = bw, txdat = as.data.frame(df_sample[, &quot;l&quot;]), tydat = df_sample$y, tzdat = as.data.frame(df_sample[, c(&quot;k&quot;, &quot;inv&quot;)])) C.1 gmmパッケージの解説 gmmの使い方はヘルプを見れば十分なのだが, タダで見られてかつ日本語のGMMの解説は少なく, 非線形GMMの解説は一層少ない. そういうものを求める人のためにここで少しだけ解説しておく. まず, 線形の場合はlm()などと同じようにformulaオブジェクトでモーメント条件を指定できる. 例えば, \\[\\begin{aligned} \\mathrm{E}(y_{i}-\\alpha-\\beta x_{i})\\begin{bmatrix}z_{i,1}\\\\ z_{i,2}\\\\ z_{i,3} \\end{bmatrix}= &amp; \\mathbf{0}\\end{aligned}\\] のようなモーメント条件をもとにGMM推定したい場合は, gmm(y~ 1 + x| z1 + z2 + z3, x = data) となる52. data はデータフレームまたはmatrixで与える. 非線形モデルの場合はこのようにモデルをformulaで表現できないため, 代わりに標本モーメントを返す関数を与える. この関数関数は第1, 第2引数にそれぞれパラメータと入力データを与て\\(N\\times q\\)行列を返すものが要求される. \\(N\\)は入力データの件数, \\(q\\)はモーメント式の本数である. つまり上記の期待値の部分で, \\[\\begin{aligned} m_{i}(\\alpha,\\beta;x_{i}):= &amp; (y_{i}-\\alpha-\\beta x_{i})\\begin{bmatrix}z_{i,1}\\\\ z_{i,2}\\\\ z_{i,3} \\end{bmatrix}\\end{aligned}\\] という部分であり, 返す行列は \\[\\begin{aligned} \\begin{bmatrix}m_{1}z_{1,1} &amp; m_{1}z_{1,2} &amp; m_{1}z_{1,3}\\\\ m_{2}z_{2,1} &amp; m_{2}z_{2,2} &amp; m_{2}z_{2,3}\\\\ \\vdots &amp; \\vdots &amp; \\vdots\\\\ m_{N}z_{N,1} &amp; m_{N}z_{N,2} &amp; m_{Z}z_{N,3} \\end{bmatrix}\\end{aligned}\\] という形になる. 非線形GMMとは\\(m_{i}(\\theta,x_{i})\\)の部分について, 例えば\\(m_{i}(\\theta,x_{i}):=(y_{i}-\\alpha-\\gamma\\beta x_{i})\\begin{bmatrix}z_{i,1} &amp; \\cdots &amp; z_{i,3}\\end{bmatrix}^{\\top}\\)のような非線形関数の場合を指す. この\\(m_{i}\\)の標本平均の重み付きノルム\\(F_{n}\\)を目的関数として最小化するのがGMMである53. \\[\\begin{aligned} F_{n}(\\alpha,\\beta)= &amp; \\left[\\frac{1}{N}\\sum_{i=1}^{N}m_{i}(\\theta,x_{i})\\right]^{\\top}\\hat{\\mathbf{W}}^{-1}\\left[\\frac{1}{N}\\sum_{i=1}^{N}m_{i}(\\theta,x_{i})\\right]\\end{aligned}\\] 非線形GMMはニュートン法でも計算できるため, 目的関数\\(F_{n}(\\cdots)\\)を計算する関数さえ作れば, 係数だけならgmmパッケージを使わなくともoptim()で簡単に推定できる. そこで, 念のためoptim()も使って検算するのも良いだろう. "]
]
